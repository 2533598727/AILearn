{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#sigmoid function \n",
    "def sigmoid(x):\n",
    "    # 对大的正值和负值进行特殊处理，避免溢出\n",
    "     # 限制输入范围，防止exp计算溢出\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sigmoid derivative\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))  # Derivative of sigmoid function: f'(x) = f(x) * (1 - f(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集的样本数 209\n",
      "测试集的样本数 50\n",
      "train_set_y的维度 (1, 209)\n",
      "test_set_y的维度 (1, 50)\n",
      "train_set_x_orig的维度 (209, 64, 64, 3)\n",
      "test_set_x_orig的维度 (50, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "import scipy\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "import data\n",
    "load_dataset = data.load_dataset\n",
    "\n",
    "train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()\n",
    "print(\"训练集的样本数\", train_set_x_orig.shape[0])\n",
    "print(\"测试集的样本数\", test_set_x_orig.shape[0])\n",
    "print(\"train_set_y的维度\", train_set_y.shape)\n",
    "print(\"test_set_y的维度\", test_set_y.shape)\n",
    "print(\"train_set_x_orig的维度\", train_set_x_orig.shape)\n",
    "print(\"test_set_x_orig的维度\", test_set_x_orig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12288, 209) (12288, 50)\n"
     ]
    }
   ],
   "source": [
    "#转换成一维向量\n",
    "train_x = train_set_x_orig.reshape(train_set_x_orig.shape[0], -1).T\n",
    "test_x = test_set_x_orig.reshape(test_set_x_orig.shape[0], -1).T\n",
    "print(train_x.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#归一化处理\n",
    "train_x = train_x/255.\n",
    "test_x = test_x/255.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让模型训练更稳定：不同像素的数值范围一致，避免因某一通道（或特征）数值过大而主导模型学习，提升梯度下降的收敛效率。\n",
    "符合模型预期：很多机器学习模型（尤其是神经网络）的激活函数对 [0,1] 区间的输入更友好，能减少数值不稳定的风险。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化网网络参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_with_zeros(shape):\n",
    "    \"\"\"\n",
    "    创建一个形状为(shape,1) 的 w 矩阵，b=0\n",
    "    \"\"\"\n",
    "    w = np.zeros((shape, 1))\n",
    "    b = 0\n",
    "\n",
    "    #检查\n",
    "    assert(w.shape == (shape, 1))\n",
    "    assert(isinstance(b, float) or isinstance(b, int))\n",
    "\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前向和方向传播\n",
    "根据损失函数、前后向传播向量化代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def propagate(w,b,X,Y):\n",
    "    Z = np.dot(w.T,X) + b\n",
    "    A = sigmoid(Z)\n",
    "    dZ = A - Y\n",
    "    dw = np.dot(X,dZ.T) / X.shape[1]\n",
    "    db = np.sum(dZ) / X.shape[1]\n",
    "    cost = -1*(np.sum(Y * np.log(A) + (1 - Y) * np.log(1 - A)) )/ X.shape[1]\n",
    "    grads = {\n",
    "        \"dw\": dw,\n",
    "        \"db\": db\n",
    "    }\n",
    "    return grads,cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 预测函数\n",
    "利用得出的参数来进行测试 得出准确率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, b, X):\n",
    "    '''\n",
    "    预测函数\n",
    "    :param w: 权重数组\n",
    "    :param b: 偏置\n",
    "    :param X: 图片的特征数据\n",
    "    :return:\n",
    "    Y_predicition: 预测是否为猫，返回值为0或1\n",
    "    p: 预测为猫的概率\n",
    "    '''\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    for i in range(A.shape[1]):\n",
    "        if A[0, i] <= 0.5:\n",
    "            Y_prediction[0, i] = 0\n",
    "        else:\n",
    "            Y_prediction[0, i] = 1\n",
    "    assert (Y_prediction.shape == (1, m))\n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 优化过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize(w, b, X, Y, num_iterations, learning_rate):\n",
    "    \"\"\"\n",
    "    梯度下降算法更新参数\n",
    "    :param w: 权重数组\n",
    "    :param b: 偏置bias\n",
    "    :param X: 图片的特征数据\n",
    "    :param Y: 图片的标签数据\n",
    "    :param num_iterations: 优化迭代次数\n",
    "    :param learning_rate: 学习率\n",
    "    :return:    params: 优化后的w和b\n",
    "                costs: 每迭代100次，记录一次成本\n",
    "    \"\"\"\n",
    "\n",
    "    costs = []\n",
    "    for i in range(num_iterations):\n",
    "        grads, cost = propagate(w, b, X, Y)\n",
    "        dw = grads[\"dw\"]\n",
    "        db = grads[\"db\"]\n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "            print(\"优化%d次后成本是：%f\" % (i, cost))\n",
    "\n",
    "    params = {\n",
    "        \"w\": w,\n",
    "        \"b\": b\n",
    "    }\n",
    "    grads = {\n",
    "        \"dw\": dw,\n",
    "        \"db\": db\n",
    "    }\n",
    "    return params,grads,costs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 整体逻辑实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train, Y_train, X_test, Y_test, num_iterations=2001, learning_rate=0.5):\n",
    "    ###开始\n",
    "    #初始化参数\n",
    "    w,b=initialize_with_zeros(X_train.shape[0])\n",
    "    #梯度下降\n",
    "    params,grads,costs = optimize(w,b,X_train,Y_train,num_iterations,learning_rate)\n",
    "    \n",
    "    w = params[\"w\"]\n",
    "    b = params[\"b\"]\n",
    "    \n",
    "    #预测\n",
    "    Y_prediction_train = predict(w, b, X_train)\n",
    "    Y_prediction_test  = predict(w, b, X_test)\n",
    "    ###结束\n",
    "\n",
    "    print(\"训练集准确率：{}\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"测试集准确率：{}\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "\n",
    "    d = {\"costs\": costs,\n",
    "         \"Y_prediction_test\": Y_prediction_test,\n",
    "         \"Y_prediction_train\": Y_prediction_train,\n",
    "         \"w\": w,\n",
    "         \"b\": b,\n",
    "         \"learning_rate\": learning_rate,\n",
    "         \"num_iterations\": num_iterations}  \n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 测试"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "优化0次后成本是：0.693147\n",
      "优化100次后成本是：0.584508\n",
      "优化200次后成本是：0.466949\n",
      "优化300次后成本是：0.376007\n",
      "优化400次后成本是：0.331463\n",
      "优化500次后成本是：0.303273\n",
      "优化600次后成本是：0.279880\n",
      "优化700次后成本是：0.260042\n",
      "优化800次后成本是：0.242941\n",
      "优化900次后成本是：0.228004\n",
      "优化1000次后成本是：0.214820\n",
      "优化1100次后成本是：0.203078\n",
      "优化1200次后成本是：0.192544\n",
      "优化1300次后成本是：0.183033\n",
      "优化1400次后成本是：0.174399\n",
      "优化1500次后成本是：0.166521\n",
      "优化1600次后成本是：0.159305\n",
      "优化1700次后成本是：0.152667\n",
      "优化1800次后成本是：0.146542\n",
      "优化1900次后成本是：0.140872\n",
      "优化2000次后成本是：0.135608\n",
      "优化2100次后成本是：0.130708\n",
      "优化2200次后成本是：0.126137\n",
      "优化2300次后成本是：0.121861\n",
      "优化2400次后成本是：0.117855\n",
      "优化2500次后成本是：0.114093\n",
      "优化2600次后成本是：0.110554\n",
      "优化2700次后成本是：0.107219\n",
      "优化2800次后成本是：0.104072\n",
      "优化2900次后成本是：0.101097\n",
      "优化3000次后成本是：0.098280\n",
      "优化3100次后成本是：0.095610\n",
      "优化3200次后成本是：0.093075\n",
      "优化3300次后成本是：0.090667\n",
      "优化3400次后成本是：0.088374\n",
      "优化3500次后成本是：0.086190\n",
      "优化3600次后成本是：0.084108\n",
      "优化3700次后成本是：0.082119\n",
      "优化3800次后成本是：0.080219\n",
      "优化3900次后成本是：0.078402\n",
      "优化4000次后成本是：0.076662\n",
      "优化4100次后成本是：0.074994\n",
      "优化4200次后成本是：0.073395\n",
      "优化4300次后成本是：0.071860\n",
      "优化4400次后成本是：0.070385\n",
      "优化4500次后成本是：0.068968\n",
      "优化4600次后成本是：0.067604\n",
      "优化4700次后成本是：0.066291\n",
      "优化4800次后成本是：0.065027\n",
      "优化4900次后成本是：0.063807\n",
      "优化5000次后成本是：0.062631\n",
      "优化5100次后成本是：0.061496\n",
      "优化5200次后成本是：0.060400\n",
      "优化5300次后成本是：0.059341\n",
      "优化5400次后成本是：0.058317\n",
      "优化5500次后成本是：0.057327\n",
      "优化5600次后成本是：0.056368\n",
      "优化5700次后成本是：0.055440\n",
      "优化5800次后成本是：0.054541\n",
      "优化5900次后成本是：0.053669\n",
      "优化6000次后成本是：0.052824\n",
      "优化6100次后成本是：0.052005\n",
      "优化6200次后成本是：0.051209\n",
      "优化6300次后成本是：0.050436\n",
      "优化6400次后成本是：0.049686\n",
      "优化6500次后成本是：0.048957\n",
      "优化6600次后成本是：0.048248\n",
      "优化6700次后成本是：0.047559\n",
      "优化6800次后成本是：0.046888\n",
      "优化6900次后成本是：0.046236\n",
      "优化7000次后成本是：0.045601\n",
      "优化7100次后成本是：0.044982\n",
      "优化7200次后成本是：0.044380\n",
      "优化7300次后成本是：0.043793\n",
      "优化7400次后成本是：0.043220\n",
      "优化7500次后成本是：0.042662\n",
      "优化7600次后成本是：0.042118\n",
      "优化7700次后成本是：0.041587\n",
      "优化7800次后成本是：0.041069\n",
      "优化7900次后成本是：0.040563\n",
      "优化8000次后成本是：0.040069\n",
      "优化8100次后成本是：0.039587\n",
      "优化8200次后成本是：0.039116\n",
      "优化8300次后成本是：0.038655\n",
      "优化8400次后成本是：0.038205\n",
      "优化8500次后成本是：0.037765\n",
      "优化8600次后成本是：0.037335\n",
      "优化8700次后成本是：0.036914\n",
      "优化8800次后成本是：0.036502\n",
      "优化8900次后成本是：0.036099\n",
      "优化9000次后成本是：0.035704\n",
      "优化9100次后成本是：0.035318\n",
      "优化9200次后成本是：0.034940\n",
      "优化9300次后成本是：0.034570\n",
      "优化9400次后成本是：0.034207\n",
      "优化9500次后成本是：0.033851\n",
      "优化9600次后成本是：0.033503\n",
      "优化9700次后成本是：0.033161\n",
      "优化9800次后成本是：0.032826\n",
      "优化9900次后成本是：0.032498\n",
      "训练集准确率：100.0\n",
      "测试集准确率：70.0\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.005\n",
    "num_iterations = 10000\n",
    "d = model(train_x,train_set_y,test_x,test_set_y,num_iterations,learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
