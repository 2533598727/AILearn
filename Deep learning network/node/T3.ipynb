{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mnist手写数字识别神经网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['image', 'label'])\n",
      "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x26D5179BA10>\n",
      "5\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 400x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from random import sample\n",
    "from datasets import load_from_disk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "dataset  = load_from_disk(\"D:/AILearn/Deep learning network/node/data/mnist\")\n",
    "\n",
    "train_data = dataset[\"train\"]\n",
    "test_data = dataset[\"test\"]\n",
    "sample = train_data[0]\n",
    "print(sample.keys())\n",
    "print(sample[\"image\"])\n",
    "print(sample[\"label\"])\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.imshow(sample[\"image\"],cmap=\"gray\")  # 使用灰度色彩映射\n",
    "plt.title(f'label: {sample[\"label\"]}')\n",
    "plt.axis('off')  # 不显示坐标轴\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 确定网络结构以及形状\n",
    "隐藏层参数 W(784,64) b(1,64)\n",
    "输出层参数 W(64,10) b(1,10)\n",
    "softmax -> 概率值  \n",
    "### 流程\n",
    "1. 获取数据\n",
    "2. 前向传播：网格结构定义\n",
    "3. 损失计算\n",
    "4. 反向传播 梯度下降优化\n",
    "功能性模块：\n",
    "· 准确率计算\n",
    "· Tensorboard可视化\n",
    "·  训练模型保存 加载 预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def transform_example(example):\n",
    "    example['image'] = torchvision.transforms.ToTensor()(example['image'])\n",
    "    example['image'] = torchvision.transforms.Normalize(mean=[0.5], std = [0.5])(example['image'])\n",
    "    example['label'] = torch.tensor(example['label'], dtype=torch.int64)\n",
    "    return example\n",
    "\n",
    "train = train_data.map(transform_example)\n",
    "test = test_data.map(transform_example)\n",
    "\n",
    "train.set_format(type='torch')\n",
    "test.set_format(type='torch')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepNN(torch.nn.Module):\n",
    "    def __init__(self,input_size = 784,hidden_size = [128,64],output_size = 10):\n",
    "        super(DeepNN,self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size,hidden_size[0])\n",
    "        self.fc2 = torch.nn.Linear(hidden_size[0],hidden_size[1])\n",
    "        self.fc3 = torch.nn.Linear(hidden_size[1],output_size)\n",
    "        self.dropout = torch.nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = x.view(-1,784) #将输入数据展平为一维向量\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = DeepNN().to(device)\n",
    "criterion = nn.CrossEntropyLoss() #交叉熵损失函数\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=0.01) #随机梯度下降优化器\n",
    "epoches = 1#训练轮数\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def train(model,train_loader,criterion,optimizer,epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(train_loader):\n",
    "            inputs, labels = data[\"image\"].to(device), data[\"label\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward() #封装了梯度计算\n",
    "            optimizer.step() #根据梯度更新参数\n",
    "\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % 100 == 99:    # 每100个batch打印一次\n",
    "                #print(model.fc1.weight.grad)  # 查看第一个全连接层权重的梯度\n",
    "                #print(model.fc1.bias.grad)    # 查看第一个全连接层偏置的梯度\n",
    "                print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 100))  \n",
    "                running_loss = 0.0\n",
    "    print('Finished Training')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model,test_loader):\n",
    "    model.eval()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in test_loader:\n",
    "            images, labels = data['image'].to(device), data['label'].to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0037,  0.0000,  0.0000,  0.0000, -0.0013,  0.0000,\n",
      "         0.0000, -0.0018,  0.0000,  0.0034,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0004,  0.0000,  0.0000, -0.0012,  0.0000,  0.0000,  0.0000,  0.0001,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0018,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0053,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0142,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0014,  0.0000, -0.0056, -0.0022, -0.0070,  0.0000,  0.0000,  0.0000,\n",
      "        -0.0011, -0.0114,  0.0000,  0.0000, -0.0009,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0088, -0.0065, -0.0011,  0.0000,  0.0000,  0.0056,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "[1,   100] loss: 1.381\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000, -0.0018,  0.0000,  0.0000,  0.0000, -0.0045,  0.0000,\n",
      "         0.0000, -0.0004,  0.0000, -0.0020,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0007,  0.0000,  0.0000,  0.0000, -0.0154,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0027,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000, -0.0029,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000, -0.0095,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0027,  0.0000,  0.0000,  0.0009, -0.0006,  0.0000,  0.0000,  0.0000,\n",
      "         0.0047,  0.0392,  0.0000,  0.0000, -0.0008,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.0133,  0.0054, -0.0055,  0.0000,  0.0000, -0.0010,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000])\n",
      "[1,   200] loss: 0.863\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[50]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43mepoches\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m test(model,test_loader)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[48]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(model, train_loader, criterion, optimizer, epochs)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[32m     14\u001b[39m     running_loss = \u001b[32m0.0\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mimage\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:790\u001b[39m, in \u001b[36m_SingleProcessDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    788\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    789\u001b[39m     index = \u001b[38;5;28mself\u001b[39m._next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[32m    791\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m    792\u001b[39m         data = _utils.pin_memory.pin_memory(data, \u001b[38;5;28mself\u001b[39m._pin_memory_device)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[39m, in \u001b[36m_MapDatasetFetcher.fetch\u001b[39m\u001b[34m(self, possibly_batched_index)\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.auto_collation:\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.dataset, \u001b[33m\"\u001b[39m\u001b[33m__getitems__\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.dataset.__getitems__:\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m         data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     52\u001b[39m         data = [\u001b[38;5;28mself\u001b[39m.dataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\arrow_dataset.py:2863\u001b[39m, in \u001b[36mDataset.__getitems__\u001b[39m\u001b[34m(self, keys)\u001b[39m\n\u001b[32m   2861\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__getitems__\u001b[39m(\u001b[38;5;28mself\u001b[39m, keys: \u001b[38;5;28mlist\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m:\n\u001b[32m   2862\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Can be used to get a batch using a list of integers indices.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2863\u001b[39m     batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[34;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2864\u001b[39m     n_examples = \u001b[38;5;28mlen\u001b[39m(batch[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(batch))])\n\u001b[32m   2865\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m [{col: array[i] \u001b[38;5;28;01mfor\u001b[39;00m col, array \u001b[38;5;129;01min\u001b[39;00m batch.items()} \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_examples)]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\arrow_dataset.py:2859\u001b[39m, in \u001b[36mDataset.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   2857\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._format_type \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._format_type \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33marrow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpandas\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mpolars\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m   2858\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m Column(\u001b[38;5;28mself\u001b[39m, key)\n\u001b[32m-> \u001b[39m\u001b[32m2859\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\arrow_dataset.py:2841\u001b[39m, in \u001b[36mDataset._getitem\u001b[39m\u001b[34m(self, key, **kwargs)\u001b[39m\n\u001b[32m   2839\u001b[39m formatter = get_formatter(format_type, features=\u001b[38;5;28mself\u001b[39m._info.features, **format_kwargs)\n\u001b[32m   2840\u001b[39m pa_subtable = query_table(\u001b[38;5;28mself\u001b[39m._data, key, indices=\u001b[38;5;28mself\u001b[39m._indices)\n\u001b[32m-> \u001b[39m\u001b[32m2841\u001b[39m formatted_output = \u001b[43mformat_table\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpa_subtable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mformat_columns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_all_columns\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_all_columns\u001b[49m\n\u001b[32m   2843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2844\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:658\u001b[39m, in \u001b[36mformat_table\u001b[39m\u001b[34m(table, key, formatter, format_columns, output_all_columns)\u001b[39m\n\u001b[32m    656\u001b[39m python_formatter = PythonFormatter(features=formatter.features)\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m format_columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m658\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mformatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquery_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mquery_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    659\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mcolumn\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    660\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m format_columns:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\formatting.py:415\u001b[39m, in \u001b[36mFormatter.__call__\u001b[39m\u001b[34m(self, pa_table, query_type)\u001b[39m\n\u001b[32m    413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.format_column(pa_table)\n\u001b[32m    414\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m query_type == \u001b[33m\"\u001b[39m\u001b[33mbatch\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m415\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpa_table\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:266\u001b[39m, in \u001b[36mTorchFormatter.format_batch\u001b[39m\u001b[34m(self, pa_table)\u001b[39m\n\u001b[32m    264\u001b[39m batch = \u001b[38;5;28mself\u001b[39m.numpy_arrow_extractor().extract_batch(pa_table)\n\u001b[32m    265\u001b[39m batch = \u001b[38;5;28mself\u001b[39m.python_features_decoder.decode_batch(batch)\n\u001b[32m--> \u001b[39m\u001b[32m266\u001b[39m batch = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrecursive_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    267\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m column_name \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[32m    268\u001b[39m     batch[column_name] = \u001b[38;5;28mself\u001b[39m._consolidate(batch[column_name])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:249\u001b[39m, in \u001b[36mTorchFormatter.recursive_tensorize\u001b[39m\u001b[34m(self, data_struct)\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrecursive_tensorize\u001b[39m(\u001b[38;5;28mself\u001b[39m, data_struct: \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    248\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Public interface maintaining compatibility.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recursive_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_struct\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:242\u001b[39m, in \u001b[36mTorchFormatter._recursive_tensorize\u001b[39m\u001b[34m(self, data_struct)\u001b[39m\n\u001b[32m    240\u001b[39m \u001b[38;5;66;03m# Handle dictionaries\u001b[39;00m\n\u001b[32m    241\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {key: \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recursive_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m data_struct.items()}\n\u001b[32m    244\u001b[39m \u001b[38;5;66;03m# Base case: tensorize the leaf value\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tensorize(data_struct)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:234\u001b[39m, in \u001b[36mTorchFormatter._recursive_tensorize\u001b[39m\u001b[34m(self, data_struct)\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, np.ndarray):\n\u001b[32m    232\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data_struct.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    233\u001b[39m         \u001b[38;5;66;03m# Use list comprehension instead of map_nested\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         result = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recursive_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_struct]\n\u001b[32m    235\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consolidate(result)\n\u001b[32m    236\u001b[39m \u001b[38;5;66;03m# Handle lists and tuples\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:234\u001b[39m, in \u001b[36mTorchFormatter._recursive_tensorize\u001b[39m\u001b[34m(self, data_struct)\u001b[39m\n\u001b[32m    231\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, np.ndarray):\n\u001b[32m    232\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data_struct.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    233\u001b[39m         \u001b[38;5;66;03m# Use list comprehension instead of map_nested\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m         result = [\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_recursive_tensorize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_struct]\n\u001b[32m    235\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._consolidate(result)\n\u001b[32m    236\u001b[39m \u001b[38;5;66;03m# Handle lists and tuples\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:235\u001b[39m, in \u001b[36mTorchFormatter._recursive_tensorize\u001b[39m\u001b[34m(self, data_struct)\u001b[39m\n\u001b[32m    232\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data_struct.dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    233\u001b[39m         \u001b[38;5;66;03m# Use list comprehension instead of map_nested\u001b[39;00m\n\u001b[32m    234\u001b[39m         result = [\u001b[38;5;28mself\u001b[39m._recursive_tensorize(item) \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m data_struct]\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_consolidate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[38;5;66;03m# Handle lists and tuples\u001b[39;00m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_struct, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\mi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\datasets\\formatting\\torch_formatter.py:66\u001b[39m, in \u001b[36mTorchFormatter._consolidate\u001b[39m\u001b[34m(self, column)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;66;03m# Fast check: if all tensors have same shape, dtype, and device, we can stack\u001b[39;00m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\n\u001b[32m     60\u001b[39m     \u001b[38;5;28misinstance\u001b[39m(x, torch.Tensor)\n\u001b[32m     61\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m x.shape == first.shape\n\u001b[32m   (...)\u001b[39m\u001b[32m     64\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m column\n\u001b[32m     65\u001b[39m ):\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m column\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "train(model,train_loader,criterion,optimizer,epoches)\n",
    "\n",
    "test(model,test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
